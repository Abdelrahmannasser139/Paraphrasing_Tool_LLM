{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FLc2TPY252T",
        "outputId": "8af7fdee-001a-451b-91b6-fa44bb04a6ae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `llama 1b` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `llama 1b`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "# Load tokenizer and model from HuggingFace\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
        "\n",
        "# üì• User Input: Enter Document Text\n",
        "document = input(\"Enter your document text for paraphrasing:\\n\")\n",
        "\n",
        "# üìä Split the document into smaller chunks\n",
        "def split_into_chunks(text, max_tokens=750):\n",
        "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=False).input_ids[0]\n",
        "    chunks = []\n",
        "    for i in range(0, len(tokens), max_tokens):\n",
        "        chunk = tokens[i:i + max_tokens]\n",
        "        chunks.append(tokenizer.decode(chunk, skip_special_tokens=True))\n",
        "    return chunks\n",
        "\n",
        "# üõ†Ô∏è Paraphrase each chunk\n",
        "paraphrased_chunks = []\n",
        "chunks = split_into_chunks(document)\n",
        "\n",
        "for i, chunk in enumerate(chunks):\n",
        "    # Add a context transition if not the first chunk\n",
        "    if i > 0:\n",
        "        chunk = chunks[i-1][-100:] + \"\\n\" + chunk  # Add previous chunk's tail for context\n",
        "\n",
        "    prompt = (\n",
        "        \"You are an AI assistant trained for paraphrasing.\\n\"\n",
        "        f\"Original Text:\\n{chunk}\\n\"\n",
        "        \"Paraphrased Text:\"\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=600)\n",
        "    output = model.generate(\n",
        "        **inputs,\n",
        "        max_length=1000,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    paraphrased = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    paraphrased = paraphrased.split(\"Paraphrased Text:\")[-1].strip()\n",
        "    paraphrased_chunks.append(paraphrased)\n",
        "\n",
        "# üìù Combine the paraphrased chunks into one document\n",
        "paraphrased_document = \"\\n\".join(paraphrased_chunks)\n",
        "\n",
        "# üì§ Display paraphrased document\n",
        "print(\"\\n--- Paraphrased Document ---\\n\")\n",
        "print(paraphrased_document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4uiEsfn48vy",
        "outputId": "47040dcb-6feb-4b44-a824-470f2c112bfa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your document text for paraphrasing:\n",
            "There are beautiful things above and roundabout them; and if they gradually grow to feel that the whole world is nothing but muck, their power of usefulness is gone. If the whole picture is painted black there remains no hue whereby to single out the rascals for distinction from their fellows.  \n",
            "\n",
            "--- Paraphrased Document ---\n",
            "\n",
            "There are amazing things in the world; however, as they grow more and more, they start to lose their usefulness. If everything is painted black, it's difficult to distinguish between good and bad people. The beauty and wonder of the world are overshadowed by the dirt and ugliness that surrounds us.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install transformers streamlit ngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtVwDXx5Iuk9",
        "outputId": "ac152740-7819-43ff-f4f0-5303b012b0b1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting ngrok\n",
            "  Downloading ngrok-1.4.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.18.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ngrok-1.4.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, ngrok, pydeck, streamlit\n",
            "Successfully installed ngrok-1.4.0 pydeck-0.9.1 streamlit-1.41.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load the tokenizer and model\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
        "    return tokenizer, model\n",
        "\n",
        "tokenizer, model = load_model()\n",
        "\n",
        "# Streamlit App\n",
        "st.title(\"üìù Paraphrasing Assistant with LLaMA ü§ñ\")\n",
        "\n",
        "user_input = st.text_area(\"Enter your text to paraphrase:\", height=200)\n",
        "\n",
        "if st.button(\"Paraphrase\"):\n",
        "    if user_input:\n",
        "        with st.spinner(\"Paraphrasing...\"):\n",
        "            prompt = (\n",
        "                \"You are an AI assistant skilled in paraphrasing. \"\n",
        "                \"Your task is to rephrase the given text while preserving its original style, tone, and nuance.\\n\"\n",
        "                f\"Original Text:\\n{user_input}\\n\"\n",
        "                \"Paraphrased Text:\"\n",
        "            )\n",
        "            inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=600)\n",
        "            output = model.generate(\n",
        "                **inputs,\n",
        "                max_length=600,\n",
        "                do_sample=True,\n",
        "                temperature=0.7,\n",
        "                top_p=0.9,\n",
        "                pad_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "            paraphrased = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "            paraphrased = paraphrased.split(\"Paraphrased Text:\")[-1].strip()\n",
        "\n",
        "            st.success(\"Paraphrasing Complete!\")\n",
        "            st.write(\"### Paraphrased Text:\")\n",
        "            st.write(paraphrased)\n",
        "    else:\n",
        "        st.warning(\"Please enter text to paraphrase.\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"Built using **Streamlit** and **LLaMA**.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuHZx85mI76v",
        "outputId": "72e64405-1ff8-433d-e8e2-6c8e54fa0a23"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Streamlit app in the background\n",
        "!streamlit run app.py &>/dev/null &\n"
      ],
      "metadata": {
        "id": "ztnT__CtJBsQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pyngrok using pip\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOXWVsuQJKop",
        "outputId": "2133da9e-6441-4793-ee73-fa73ccc5987a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your ngrok authentication token\n",
        "!ngrok config add-authtoken 2qpruL9I6szooqm9VpbJxQ0st1c_6XFijP2MQJRMW5PqRFzXq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-El1Ai7_J5_3",
        "outputId": "d1434bb4-8bd9-415f-d748-0c5c84053864"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Streamlit app in the background\n",
        "!streamlit run app.py &>/dev/null &\n"
      ],
      "metadata": {
        "id": "BIO-l5DZKKuk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kill any existing ngrok processes\n",
        "!pkill -f ngrok\n"
      ],
      "metadata": {
        "id": "AekOElPeKbV3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear ngrok configuration\n",
        "!rm -rf /root/.ngrok2\n"
      ],
      "metadata": {
        "id": "DL4q8MZvKfAR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-authenticate with your ngrok token\n",
        "!ngrok config add-authtoken 2qpruL9I6szooqm9VpbJxQ0st1c_6XFijP2MQJRMW5PqRFzXq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7Sr2u4AKg-Z",
        "outputId": "fee08613-b2c5-4598-dd1e-2237cd2653ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Streamlit app\n",
        "!streamlit run app.py &>/dev/null &\n"
      ],
      "metadata": {
        "id": "xZCFT19OKi9p"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers streamlit ngrok pyngrok --quiet\n",
        "\n",
        "# Start Streamlit on port 8501\n",
        "!streamlit run app.py --server.port=8501 --server.address=0.0.0.0 &>/dev/null &\n",
        "\n",
        "# Start ngrok tunnel\n",
        "!ngrok http 8501 --log=stdout\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpdW1bnuLjg7",
        "outputId": "556f7dff-0697-4036-bf53-e7e0dcef5995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mINFO\u001b[0m[12-28|07:32:29] no configuration paths supplied \n",
            "\u001b[32mINFO\u001b[0m[12-28|07:32:29] using configuration at default config path \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml\n",
            "\u001b[32mINFO\u001b[0m[12-28|07:32:29] open config file                         \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml \u001b[32merr\u001b[0m=nil\n",
            "t=2024-12-28T07:32:30+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "t=2024-12-28T07:32:30+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "t=2024-12-28T07:32:30+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "t=2024-12-28T07:32:30+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=command_line addr=http://localhost:8501 url=https://4b7d-34-125-2-185.ngrok-free.app\n",
            "t=2024-12-28T07:32:37+0000 lvl=info msg=\"join connections\" obj=join id=6ff82c1a525c l=127.0.0.1:8501 r=41.232.44.90:59979\n",
            "t=2024-12-28T07:32:37+0000 lvl=info msg=\"join connections\" obj=join id=ab02880453dc l=127.0.0.1:8501 r=41.232.44.90:59979\n",
            "t=2024-12-28T07:32:37+0000 lvl=info msg=\"join connections\" obj=join id=7780956a031b l=127.0.0.1:8501 r=41.232.44.90:59979\n",
            "t=2024-12-28T07:32:37+0000 lvl=info msg=\"join connections\" obj=join id=651a71d14bc8 l=127.0.0.1:8501 r=41.232.44.90:59979\n",
            "t=2024-12-28T07:32:37+0000 lvl=info msg=\"join connections\" obj=join id=5a504543a76e l=127.0.0.1:8501 r=41.232.44.90:59979\n",
            "t=2024-12-28T07:32:39+0000 lvl=info msg=\"join connections\" obj=join id=ace7d88e8731 l=127.0.0.1:8501 r=41.232.44.90:59979\n",
            "t=2024-12-28T07:32:39+0000 lvl=info msg=\"join connections\" obj=join id=075902c64841 l=127.0.0.1:8501 r=41.232.44.90:59991\n",
            "t=2024-12-28T07:33:53+0000 lvl=info msg=\"join connections\" obj=join id=612398c8b46a l=127.0.0.1:8501 r=41.232.44.90:59979\n",
            "t=2024-12-28T07:33:53+0000 lvl=info msg=\"join connections\" obj=join id=f385c91cf6e4 l=127.0.0.1:8501 r=41.232.44.90:59979\n",
            "t=2024-12-28T07:33:53+0000 lvl=info msg=\"join connections\" obj=join id=6e95f2784154 l=127.0.0.1:8501 r=41.232.44.90:59979\n",
            "t=2024-12-28T07:33:53+0000 lvl=info msg=\"join connections\" obj=join id=70683a7c84ba l=127.0.0.1:8501 r=41.232.44.90:59979\n",
            "t=2024-12-28T07:33:53+0000 lvl=info msg=\"join connections\" obj=join id=9facfa59ef61 l=127.0.0.1:8501 r=41.232.44.90:59979\n",
            "t=2024-12-28T07:33:53+0000 lvl=info msg=\"join connections\" obj=join id=616a6ceaa2a3 l=127.0.0.1:8501 r=41.232.44.90:59979\n",
            "t=2024-12-28T07:33:53+0000 lvl=info msg=\"join connections\" obj=join id=3122a62e6ff4 l=127.0.0.1:8501 r=41.232.44.90:59979\n",
            "t=2024-12-28T07:33:53+0000 lvl=info msg=\"join connections\" obj=join id=6de48b2c0bd7 l=127.0.0.1:8501 r=41.232.44.90:59979\n"
          ]
        }
      ]
    }
  ]
}